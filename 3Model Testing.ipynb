{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import audioop\n",
    "import pyaudio\n",
    "import wave\n",
    "import speech_recognition as sr\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_MODEL_PATH = \"batch8 175.h5\"\n",
    "SAMPLES_TO_CONSIDER = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [],
   "source": [
    "class _Keyword_Spotting_Service:\n",
    "\n",
    "    model = None\n",
    "    _mapping = [\n",
    "        \"Kanan\",\n",
    "        \"Kiri\",\n",
    "        \"Maju\",\n",
    "        \"Stop\"\n",
    "    ]\n",
    "    _instance = None\n",
    "\n",
    "\n",
    "    def predict(self, file_path):\n",
    "\n",
    "        # extract MFCC\n",
    "        MFCCs = self.preprocess(file_path)\n",
    "\n",
    "        # we need a 4-dim array to feed to the model for prediction: (# samples, # time steps, # coefficients, 1)\n",
    "        MFCCs = MFCCs[np.newaxis, ..., np.newaxis]\n",
    "\n",
    "        # get the predicted label\n",
    "        predictions = self.model.predict(MFCCs)\n",
    "        predicted_index = np.argmax(predictions)\n",
    "        print(predictions)\n",
    "        predicted_keyword = self._mapping[predicted_index]  \n",
    "        return predicted_keyword\n",
    "\n",
    "\n",
    "    def preprocess(self, file_path, num_mfcc=13, n_fft=2048, hop_length=512):\n",
    "\n",
    "        # load audio file\n",
    "        signal, sample_rate = librosa.load(file_path)\n",
    "\n",
    "        if len(signal) >= SAMPLES_TO_CONSIDER:\n",
    "            # ensure consistency of the length of the signal\n",
    "            signal = signal[:SAMPLES_TO_CONSIDER]\n",
    "\n",
    "            # extract MFCCs\n",
    "            MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n",
    "        return MFCCs.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Keyword_Spotting_Service():\n",
    "\n",
    "    # ensure an instance is created only the first time the factory function is called\n",
    "    if _Keyword_Spotting_Service._instance is None:\n",
    "        _Keyword_Spotting_Service._instance = _Keyword_Spotting_Service()\n",
    "        _Keyword_Spotting_Service.model = tf.keras.models.load_model(SAVED_MODEL_PATH)\n",
    "    return _Keyword_Spotting_Service._instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [],
   "source": [
    "FRAMES = []\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1\n",
    "RATE = 2250\n",
    "RECORD_SECONDS = 2\n",
    "CHUNK = 1024\n",
    "TEMPORARY_WAVE_FILENAME = \"temp.wav\"\n",
    "\n",
    "mic = sr.Microphone()\n",
    "rec = sr.Recognizer()\n",
    "audio = pyaudio.PyAudio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recording():\n",
    "    global FRAMES, FORMAT, CHUNK, CHANNELS, RATE, TEMPORARY_WAVE_FILENAME\n",
    "    try:\n",
    "        print (\"recording...\")\n",
    "        stream = audio.open(format=FORMAT, channels=CHANNELS,\n",
    "                            rate=RATE, input=True,\n",
    "                            frames_per_buffer=CHUNK)\n",
    "        for i in range(0, int(RATE / CHUNK * RECORD_SECONDS)):\n",
    "            data = stream.read(CHUNK)\n",
    "            mx = audioop.max(data, 2)\n",
    "            # print mx\n",
    "            FRAMES.append(data)\n",
    "        print (\"Finish recordings\")\n",
    "\n",
    "        stream.stop_stream()\n",
    "        stream.close()\n",
    "        audio.terminate()\n",
    "\n",
    "        waveFile = wave.open(TEMPORARY_WAVE_FILENAME, 'wb')\n",
    "        waveFile.setnchannels(CHANNELS)\n",
    "        waveFile.setsampwidth(audio.get_sample_size(FORMAT))\n",
    "        waveFile.setframerate(RATE)\n",
    "        waveFile.writeframes(b''.join(FRAMES))\n",
    "        waveFile.close()\n",
    "        del stream\n",
    "    except Exception as e:\n",
    "        print (e.message)\n",
    "        raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognise():\n",
    "    global FRAMES\n",
    "    kss = Keyword_Spotting_Service()\n",
    "    r = sr.Recognizer()\n",
    "    with sr.AudioFile(TEMPORARY_WAVE_FILENAME) as source:\n",
    "        audio = r.record(source)  # read the entire audio file\n",
    "    keyword = kss.predict(TEMPORARY_WAVE_FILENAME)\n",
    "    os.remove(TEMPORARY_WAVE_FILENAME)\n",
    "    try:\n",
    "        print(\"Perintah: \" + keyword)\n",
    "    except sr.UnknownValueError:  # speech is unintelligible\n",
    "        print(\"Tidak dapat menerjemahkan\")\n",
    "    \n",
    "    # create 2 instances of the keyword spotting service\n",
    "    \n",
    "    #kss1 = Keyword_Spotting_Service()\n",
    "\n",
    "    # check that different instances of the keyword spotting service point back to the same object (singleton)\n",
    "    #assert kss is kss1\n",
    "\n",
    "    # make a prediction\n",
    "    #keyword = kss.predict(audio)\n",
    "    #print(keyword)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recording...\n",
      "Finish recordings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_14728\\1735644397.py:39: FutureWarning: Pass y=[1.1198784e-06 2.5700620e-06 3.9386314e-06 ... 3.7597943e-02 2.3017019e-02\n",
      " 9.0650665e-03], sr=22050 as keyword args. From version 0.10 passing these as positional arguments will result in an error\n",
      "  MFCCs = librosa.feature.mfcc(signal, sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 383ms/step\n",
      "[[0.00174168 0.08270929 0.80764794 0.10790103]]\n",
      "Perintah: Maju\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    #while True :\n",
    "        recording()\n",
    "        recognise()\n",
    "        #recording2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.2 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
